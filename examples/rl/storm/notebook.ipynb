{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from omegaconf import OmegaConf\n",
    "import gymnasium\n",
    "from world_models import WorldModel\n",
    "\n",
    "import colorama\n",
    "import numpy as np\n",
    "from tinygrad import Tensor, nn\n",
    "from tinygrad.nn.state import get_parameters, get_state_dict\n",
    "\n",
    "import env_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_single_env(env_name, image_size, seed):\n",
    "  env = gymnasium.make(env_name, full_action_space=False, render_mode=\"rgb_array\", frameskip=1)\n",
    "  env = env_wrapper.SeedEnvWrapper(env, seed=seed)\n",
    "  env = env_wrapper.MaxLast2FrameSkipWrapper(env, skip=4)\n",
    "  env = gymnasium.wrappers.ResizeObservation(env, shape=image_size)\n",
    "  env = env_wrapper.LifeLossInfo(env)\n",
    "  return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_world_model(conf, action_dim):\n",
    "    return WorldModel(\n",
    "        in_channels=conf.models.world_model.in_channels,\n",
    "        action_dim=action_dim,\n",
    "        transformer_max_length=conf.models.world_model.transformer_max_length,\n",
    "        transformer_hidden_dim=conf.models.world_model.transformer_hidden_dim,\n",
    "        transformer_num_layers=conf.models.world_model.transformer_num_layers,\n",
    "        transformer_num_heads=conf.models.world_model.transformer_num_heads\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-n\", type=str, required=True)\n",
    "parser.add_argument(\"-seed\", type=int, required=True)\n",
    "parser.add_argument(\"-config_path\", type=str, required=True)\n",
    "parser.add_argument(\"-env_name\", type=str, required=True)\n",
    "parser.add_argument(\"-trajectory_path\", type=str, required=True)\n",
    "args = parser.parse_args([\n",
    "    \"-n\", \"MsPacman\",\n",
    "    \"-seed\", \"1\",\n",
    "    \"-config_path\", \"STORM.yaml\",\n",
    "    \"-env_name\", \"ALE/MsPacman-v5\",\n",
    "    \"-trajectory_path\", \"D_TRAJ/MsPacman.pkl\"\n",
    "])\n",
    "conf = OmegaConf.load(args.config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mNamespace(n='MsPacman', seed=1, config_path='STORM.yaml', env_name='ALE/MsPacman-v5', trajectory_path='D_TRAJ/MsPacman.pkl')\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(colorama.Fore.RED + str(args) + colorama.Style.RESET_ALL)\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "Tensor.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "dummy_env = build_single_env(args.env_name, conf.basic_settings.image_size, seed=0)\n",
    "action_dim = dummy_env.action_space.n.item()\n",
    "del dummy_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_model = build_world_model(conf, action_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -  encoder.conv_in.weight :  (32, 3, 4, 4)  --  None\n",
      "2 -  encoder.bn_in.weight :  (32,)  --  None\n",
      "3 -  encoder.bn_in.bias :  (32,)  --  None\n",
      "4 -  encoder.bn_in.running_mean :  (32,)  --  False\n",
      "5 -  encoder.bn_in.running_var :  (32,)  --  False\n",
      "6 -  encoder.bn_in.num_batches_tracked :  (1,)  --  False\n",
      "7 -  encoder.convs.0.weight :  (64, 32, 4, 4)  --  None\n",
      "8 -  encoder.convs.1.weight :  (128, 64, 4, 4)  --  None\n",
      "9 -  encoder.convs.2.weight :  (256, 128, 4, 4)  --  None\n",
      "10 -  encoder.bns.0.weight :  (64,)  --  None\n",
      "11 -  encoder.bns.0.bias :  (64,)  --  None\n",
      "12 -  encoder.bns.0.running_mean :  (64,)  --  False\n",
      "13 -  encoder.bns.0.running_var :  (64,)  --  False\n",
      "14 -  encoder.bns.0.num_batches_tracked :  (1,)  --  False\n",
      "15 -  encoder.bns.1.weight :  (128,)  --  None\n",
      "16 -  encoder.bns.1.bias :  (128,)  --  None\n",
      "17 -  encoder.bns.1.running_mean :  (128,)  --  False\n",
      "18 -  encoder.bns.1.running_var :  (128,)  --  False\n",
      "19 -  encoder.bns.1.num_batches_tracked :  (1,)  --  False\n",
      "20 -  encoder.bns.2.weight :  (256,)  --  None\n",
      "21 -  encoder.bns.2.bias :  (256,)  --  None\n",
      "22 -  encoder.bns.2.running_mean :  (256,)  --  False\n",
      "23 -  encoder.bns.2.running_var :  (256,)  --  False\n",
      "24 -  encoder.bns.2.num_batches_tracked :  (1,)  --  False\n",
      "25 -  storm_transformer.stem.0.weight :  (512, 1033)  --  None\n",
      "26 -  storm_transformer.stem.1.weight :  (512,)  --  None\n",
      "27 -  storm_transformer.stem.1.bias :  (512,)  --  None\n",
      "28 -  storm_transformer.stem.3.weight :  (512, 512)  --  None\n",
      "29 -  storm_transformer.stem.4.weight :  (512,)  --  None\n",
      "30 -  storm_transformer.stem.4.bias :  (512,)  --  None\n",
      "31 -  storm_transformer.position_encoding.pos_emb.weight :  (64, 512)  --  None\n",
      "32 -  storm_transformer.layer_stack.0.slf_attn.w_qs.weight :  (512, 512)  --  None\n",
      "33 -  storm_transformer.layer_stack.0.slf_attn.w_ks.weight :  (512, 512)  --  None\n",
      "34 -  storm_transformer.layer_stack.0.slf_attn.w_vs.weight :  (512, 512)  --  None\n",
      "35 -  storm_transformer.layer_stack.0.slf_attn.fc.weight :  (512, 512)  --  None\n",
      "36 -  storm_transformer.layer_stack.0.slf_attn.layer_norm.weight :  (512,)  --  None\n",
      "37 -  storm_transformer.layer_stack.0.slf_attn.layer_norm.bias :  (512,)  --  None\n",
      "38 -  storm_transformer.layer_stack.0.pos_ffn.w_1.weight :  (1024, 512)  --  None\n",
      "39 -  storm_transformer.layer_stack.0.pos_ffn.w_1.bias :  (1024,)  --  None\n",
      "40 -  storm_transformer.layer_stack.0.pos_ffn.w_2.weight :  (512, 1024)  --  None\n",
      "41 -  storm_transformer.layer_stack.0.pos_ffn.w_2.bias :  (512,)  --  None\n",
      "42 -  storm_transformer.layer_stack.0.pos_ffn.layer_norm.weight :  (512,)  --  None\n",
      "43 -  storm_transformer.layer_stack.0.pos_ffn.layer_norm.bias :  (512,)  --  None\n",
      "44 -  storm_transformer.layer_stack.1.slf_attn.w_qs.weight :  (512, 512)  --  None\n",
      "45 -  storm_transformer.layer_stack.1.slf_attn.w_ks.weight :  (512, 512)  --  None\n",
      "46 -  storm_transformer.layer_stack.1.slf_attn.w_vs.weight :  (512, 512)  --  None\n",
      "47 -  storm_transformer.layer_stack.1.slf_attn.fc.weight :  (512, 512)  --  None\n",
      "48 -  storm_transformer.layer_stack.1.slf_attn.layer_norm.weight :  (512,)  --  None\n",
      "49 -  storm_transformer.layer_stack.1.slf_attn.layer_norm.bias :  (512,)  --  None\n",
      "50 -  storm_transformer.layer_stack.1.pos_ffn.w_1.weight :  (1024, 512)  --  None\n",
      "51 -  storm_transformer.layer_stack.1.pos_ffn.w_1.bias :  (1024,)  --  None\n",
      "52 -  storm_transformer.layer_stack.1.pos_ffn.w_2.weight :  (512, 1024)  --  None\n",
      "53 -  storm_transformer.layer_stack.1.pos_ffn.w_2.bias :  (512,)  --  None\n",
      "54 -  storm_transformer.layer_stack.1.pos_ffn.layer_norm.weight :  (512,)  --  None\n",
      "55 -  storm_transformer.layer_stack.1.pos_ffn.layer_norm.bias :  (512,)  --  None\n",
      "56 -  storm_transformer.layer_norm.weight :  (512,)  --  None\n",
      "57 -  storm_transformer.layer_norm.bias :  (512,)  --  None\n",
      "58 -  dist_head.post_head.weight :  (1024, 4096)  --  None\n",
      "59 -  dist_head.post_head.bias :  (1024,)  --  None\n",
      "60 -  dist_head.prior_head.weight :  (1024, 512)  --  None\n",
      "61 -  dist_head.prior_head.bias :  (1024,)  --  None\n",
      "62 -  image_decoder.backbone.0.weight :  (4096, 1024)  --  None\n",
      "63 -  image_decoder.backbone.2.weight :  (256,)  --  None\n",
      "64 -  image_decoder.backbone.2.bias :  (256,)  --  None\n",
      "65 -  image_decoder.backbone.2.running_mean :  (256,)  --  False\n",
      "66 -  image_decoder.backbone.2.running_var :  (256,)  --  False\n",
      "67 -  image_decoder.backbone.2.num_batches_tracked :  (1,)  --  False\n",
      "68 -  image_decoder.backbone.4.weight :  (256, 128, 4, 4)  --  None\n",
      "69 -  image_decoder.backbone.5.weight :  (128,)  --  None\n",
      "70 -  image_decoder.backbone.5.bias :  (128,)  --  None\n",
      "71 -  image_decoder.backbone.5.running_mean :  (128,)  --  False\n",
      "72 -  image_decoder.backbone.5.running_var :  (128,)  --  False\n",
      "73 -  image_decoder.backbone.5.num_batches_tracked :  (1,)  --  False\n",
      "74 -  image_decoder.backbone.7.weight :  (128, 64, 4, 4)  --  None\n",
      "75 -  image_decoder.backbone.8.weight :  (64,)  --  None\n",
      "76 -  image_decoder.backbone.8.bias :  (64,)  --  None\n",
      "77 -  image_decoder.backbone.8.running_mean :  (64,)  --  False\n",
      "78 -  image_decoder.backbone.8.running_var :  (64,)  --  False\n",
      "79 -  image_decoder.backbone.8.num_batches_tracked :  (1,)  --  False\n",
      "80 -  image_decoder.backbone.10.weight :  (64, 32, 4, 4)  --  None\n",
      "81 -  image_decoder.backbone.11.weight :  (32,)  --  None\n",
      "82 -  image_decoder.backbone.11.bias :  (32,)  --  None\n",
      "83 -  image_decoder.backbone.11.running_mean :  (32,)  --  False\n",
      "84 -  image_decoder.backbone.11.running_var :  (32,)  --  False\n",
      "85 -  image_decoder.backbone.11.num_batches_tracked :  (1,)  --  False\n",
      "86 -  image_decoder.backbone.13.weight :  (32, 3, 4, 4)  --  None\n",
      "87 -  image_decoder.backbone.13.bias :  (3,)  --  None\n",
      "88 -  reward_decoder.backbone.0.weight :  (512, 512)  --  None\n",
      "89 -  reward_decoder.backbone.1.weight :  (512,)  --  None\n",
      "90 -  reward_decoder.backbone.1.bias :  (512,)  --  None\n",
      "91 -  reward_decoder.backbone.3.weight :  (512, 512)  --  None\n",
      "92 -  reward_decoder.backbone.4.weight :  (512,)  --  None\n",
      "93 -  reward_decoder.backbone.4.bias :  (512,)  --  None\n",
      "94 -  reward_decoder.head.weight :  (255, 512)  --  None\n",
      "95 -  reward_decoder.head.bias :  (255,)  --  None\n",
      "96 -  termination_decoder.backbone.0.weight :  (512, 512)  --  None\n",
      "97 -  termination_decoder.backbone.1.weight :  (512,)  --  None\n",
      "98 -  termination_decoder.backbone.1.bias :  (512,)  --  None\n",
      "99 -  termination_decoder.backbone.3.weight :  (512, 512)  --  None\n",
      "100 -  termination_decoder.backbone.4.weight :  (512,)  --  None\n",
      "101 -  termination_decoder.backbone.4.bias :  (512,)  --  None\n",
      "102 -  termination_decoder.head.weight :  (1, 512)  --  None\n",
      "103 -  termination_decoder.head.bias :  (1,)  --  None\n",
      "104 -  symlog_twohot_loss_func.bins :  (255,)  --  False\n",
      "Total updatable parameters:  79\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "updatable_count = 0\n",
    "for k, v in get_state_dict(world_model).items():\n",
    "    print(i, \"- \", k, \": \", v.shape, \" -- \", v.requires_grad)\n",
    "    if v.requires_grad is None: updatable_count += 1\n",
    "    i+=1\n",
    "print(\"Total updatable parameters: \", updatable_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# World model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur device:  CUDA\n"
     ]
    }
   ],
   "source": [
    "from tinygrad.nn.state import safe_load, load_state_dict\n",
    "\n",
    "cur_device = Tensor.randn(1).device\n",
    "print(\"cur device: \", cur_device)\n",
    "\n",
    "inputs = safe_load(\"world_model_inputs.safetensors\")\n",
    "obs, action, reward, termination = inputs[\"obs\"].to(cur_device), inputs[\"action\"].to(cur_device), inputs[\"reward\"].to(cur_device), inputs[\"termination\"].to(cur_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward time: 0.02721s\n"
     ]
    }
   ],
   "source": [
    "with Tensor.train():\n",
    "    total_loss = world_model.loss(obs, action, reward, termination, logger =None)\n",
    "    total_loss.realize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor <LB CUDA () contig:True (<BinaryOps.ADD: 1>, <buf device:CUDA size:1 dtype:dtypes.float>)> on CUDA with grad <LB CUDA () contig:True (<LoadOps.CONST: 2>, None)>>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 4, 4) No grad\n",
      "(32,) No grad\n",
      "(32,) No grad\n",
      "(32,) No grad\n",
      "(32,) No grad\n",
      "(1,) No grad\n",
      "(64, 32, 4, 4) No grad\n",
      "(128, 64, 4, 4) No grad\n",
      "(256, 128, 4, 4) No grad\n",
      "(64,) No grad\n",
      "(64,) No grad\n",
      "(64,) No grad\n",
      "(64,) No grad\n",
      "(1,) No grad\n",
      "(128,) No grad\n",
      "(128,) No grad\n",
      "(128,) No grad\n",
      "(128,) No grad\n",
      "(1,) No grad\n",
      "(256,) No grad\n",
      "(256,) No grad\n",
      "(256,) No grad\n",
      "(256,) No grad\n",
      "(1,) No grad\n",
      "(512, 1033) No grad\n",
      "(512,) No grad\n",
      "(512,) No grad\n",
      "(512, 512) No grad\n",
      "(512,) No grad\n",
      "(512,) No grad\n",
      "(64, 512) No grad\n",
      "(1, 1, 64) No grad\n",
      "(512, 512) No grad\n",
      "(512, 512) No grad\n",
      "(512, 512) No grad\n",
      "(512, 512) No grad\n",
      "(512,) No grad\n",
      "(512,) No grad\n",
      "(1024, 512) No grad\n",
      "(1024,) No grad\n",
      "(512, 1024) No grad\n",
      "(512,) No grad\n",
      "(512,) No grad\n",
      "(512,) No grad\n",
      "(512, 512) No grad\n",
      "(512, 512) No grad\n",
      "(512, 512) No grad\n",
      "(512, 512) No grad\n",
      "(512,) No grad\n",
      "(512,) No grad\n",
      "(1024, 512) No grad\n",
      "(1024,) No grad\n",
      "(512, 1024) No grad\n",
      "(512,) No grad\n",
      "(512,) No grad\n",
      "(512,) No grad\n",
      "(512,) No grad\n",
      "(512,) No grad\n",
      "(1024, 4096) No grad\n",
      "(1024,) No grad\n",
      "(1024, 512) No grad\n",
      "(1024,) No grad\n",
      "(4096, 1024) No grad\n",
      "(256,) No grad\n",
      "(256,) No grad\n",
      "(256,) No grad\n",
      "(256,) No grad\n",
      "(1,) No grad\n",
      "(256, 128, 4, 4) No grad\n",
      "(128,) No grad\n",
      "(128,) No grad\n",
      "(128,) No grad\n",
      "(128,) No grad\n",
      "(1,) No grad\n",
      "(128, 64, 4, 4) No grad\n",
      "(64,) No grad\n",
      "(64,) No grad\n",
      "(64,) No grad\n",
      "(64,) No grad\n",
      "(1,) No grad\n",
      "(64, 32, 4, 4) No grad\n",
      "(32,) No grad\n",
      "(32,) No grad\n",
      "(32,) No grad\n",
      "(32,) No grad\n",
      "(1,) No grad\n",
      "(32, 3, 4, 4) No grad\n",
      "(3,) No grad\n",
      "(512, 512) No grad\n",
      "(512,) No grad\n",
      "(512,) No grad\n",
      "(512, 512) No grad\n",
      "(512,) No grad\n",
      "(512,) No grad\n",
      "(255, 512) No grad\n",
      "(255,) No grad\n",
      "(512, 512) No grad\n",
      "(512,) No grad\n",
      "(512,) No grad\n",
      "(512, 512) No grad\n",
      "(512,) No grad\n",
      "(512,) No grad\n",
      "(1, 512) No grad\n",
      "(1,) No grad\n",
      "(255,) No grad\n",
      "No grad count:  105\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for p in get_parameters(world_model):\n",
    "    if p.grad is None:\n",
    "        i+=1\n",
    "        print(p.shape, \"No grad\")\n",
    "print(\"No grad count: \", i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
